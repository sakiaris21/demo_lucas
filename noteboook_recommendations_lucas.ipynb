{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions.split_data import split_data\n",
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from recommenders.utils.python_utils import binarize\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    rmse,\n",
    "    mae,\n",
    "    logloss,\n",
    "    rsquared,\n",
    "    exp_var\n",
    ")\n",
    "from recommenders.models.sar import SAR\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.read_excel(\"/Users/Mac/Downloads/sales_demo_new.xlsx\", nrows = 1000)\n",
    ")\n",
    "# create industries\n",
    "industries = [f\"industry_{x}\" for x in range(1, 21)]\n",
    "df[\"industry\"] = np.random.choice(industries, size = df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total customers:  195\n",
      "----------------------------------------\n",
      "Total products:  200\n",
      "----------------------------------------\n",
      "First date:  2023-01-01 00:00:00\n",
      "----------------------------------------\n",
      "Last date:  2023-01-07 00:00:00\n",
      "----------------------------------------\n",
      "total transactions:  1000\n",
      "----------------------------------------\n",
      "total columns beginning:  19\n"
     ]
    }
   ],
   "source": [
    "print(\"Total customers: \", df[\"customer_id\"].nunique())\n",
    "print(\"-\" * 40)\n",
    "print(\"Total products: \", df[\"product_id\"].nunique())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"First date: \", df[\"date\"].min())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"Last date: \", df[\"date\"].max())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"total transactions: \", df.shape[0])\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"total columns beginning: \", df.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = df.copy()\n",
    "frame_products = sales.copy()\n",
    "date_col = 'date'\n",
    "item_col = 'product_id'\n",
    "user_col = 'customer_id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_products['timestamp'] = frame_products[date_col].astype('str').\\\n",
    "                                            apply(lambda x:\n",
    "                                            int((datetime.datetime(int(x[:4]),\\\n",
    "                                            int(x[5:7]),\\\n",
    "                                            int(x[-2:]))-\\\n",
    "                                            datetime.datetime(1970, 1, 1)).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommendations_score.score_feature_engineer import SalesFeatureEngineer\n",
    "from recommendations_score.rating_functions import *\n",
    "\n",
    "processor = SalesFeatureEngineer(frame_products)\n",
    "\n",
    "processor.add_time_features()\\\n",
    "                    .add_customer_features()\\\n",
    "                    .add_behavioral_features()\\\n",
    "                    .add_preference_score()\n",
    "                    \n",
    "sales_df_class = processor.get_dataframe()\n",
    "#\n",
    "sales_df_class = compute_rating(df=sales_df_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frame_products_class = (sales_df_class[[user_col, item_col, \"timestamp\", \"rating\"]]\n",
    "                        .rename(columns={\n",
    "                        user_col:'userID',\n",
    "                        item_col:'itemID',\n",
    "                                }\n",
    "                        ).drop_duplicates()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.split_data import split_data\n",
    "train, test = split_data(table=frame_products_class.copy())\n",
    "test = test[test[\"userID\"].isin(train[\"userID\"].values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAR(\n",
    "    col_user=\"userID\",\n",
    "    col_item=\"itemID\",\n",
    "    col_rating=\"rating\",\n",
    "    col_timestamp=\"timestamp\",\n",
    "    similarity_type=\"jaccard\", \n",
    "    time_decay_coefficient=30, \n",
    "    timedecay_formula=True,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.024310541000005514 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(train.drop_duplicates())\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.009513584000018227 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "    top_k = model.recommend_k_items(test.drop_duplicates(), top_k=10, remove_seen=True) # suggest only unknown products for the customers\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))\n",
    "#\n",
    "test['itemID'] = test['itemID'].astype('int')\n",
    "#\n",
    "TOP_K = 10\n",
    "eval_map = (\n",
    "    map_at_k(\n",
    "        test,\n",
    "        top_k,\n",
    "        col_user='userID',\n",
    "        col_item='itemID',\n",
    "        col_prediction='prediction',\n",
    "        k=TOP_K\n",
    "    )\n",
    ")\n",
    "eval_ndcg = (\n",
    "    ndcg_at_k(\n",
    "        test,\n",
    "        top_k,\n",
    "        col_user='userID',\n",
    "        col_item='itemID',\n",
    "        col_rating = 'rating',\n",
    "        col_prediction='prediction', k=TOP_K)\n",
    ")\n",
    "eval_precision = precision_at_k(test, top_k, col_user='userID', col_item='itemID', col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, top_k, col_user='userID', col_item='itemID', col_prediction='prediction', k=TOP_K)\n",
    "eval_rmse = rmse(test, top_k, col_user='userID', col_item='itemID', col_rating='rating', col_prediction='prediction')\n",
    "eval_mae = mae(test, top_k, col_user='userID', col_item='itemID', col_rating='rating', col_prediction='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['userID'] = test['userID'].astype('str')\n",
    "top_k['userID'] = top_k['userID'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pr = dict()\n",
    "topk_pr = dict()\n",
    "correct_pr = dict()\n",
    "for c in test.userID.unique():\n",
    "    test_pr[c] = dict()\n",
    "    topk_pr[c] = dict()\n",
    "    correct_pr[c] = dict()\n",
    "    test_pr[c] = [test[test['userID'] == str(c)].shape[0]]\n",
    "    topk_pr[c] = [top_k[top_k['userID'] == str(c)].shape[0]]\n",
    "    correct_pr[c] = [test[(test['userID'] == str(c))&(test['itemID'].isin(top_k[top_k['userID'] == str(c)].itemID.tolist()))].shape[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "number_of_correct_prediction for sar:  58\n"
     ]
    }
   ],
   "source": [
    "print(len([v for k,v in correct_pr.items() if v != 0]))\n",
    "print('number_of_correct_prediction for sar: ', np.sum([v for k,v in correct_pr.items() if v != 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame.from_dict(test_pr).T.reset_index(names='userID_test').rename(columns={0:'Total_transactions'})\n",
    "topk_df = pd.DataFrame.from_dict(topk_pr).T.reset_index(names='userID_topk').rename(columns={0:'Total_recommendations'})\n",
    "correct_df = pd.DataFrame.from_dict(correct_pr).T.reset_index(names='userID_correct').rename(columns={0:'Total_correct'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = (\n",
    "    pd.concat([test_df, topk_df, correct_df], axis=1).drop(columns=['userID_topk', 'userID_correct'])\n",
    ")\n",
    "results_df.query(\"Total_correct > 0\").Total_correct.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\t\n",
      "Top K:\t10\n",
      "MAP:\t0.181370\n",
      "NDCG:\t0.523258\n",
      "Precision@K:\t0.192539\n",
      "Recall@K:\t0.043948\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\t\",\n",
    "      \"Top K:\\t%d\" % TOP_K,\n",
    "      \"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall,\n",
    "    #  \"RMSE:\\t%f\" % eval_rmse,\n",
    "     # \"MAE:\\t%f\" % eval_mae,\n",
    "    \n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
